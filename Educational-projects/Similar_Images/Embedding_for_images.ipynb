{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMB6vMDryHmg/4ggPrZsaqJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Evgeny-Artemov/Deep_Learning/blob/main/Educational-projects/Similar_Images/Embedding_for_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcPn9eCwD-3S"
      },
      "outputs": [],
      "source": [
        "!wget 'https://data.caltech.edu/records/mzrjq-6wc02/files/caltech-101.zip'\n",
        "!unzip '/content/caltech-101.zip'\n",
        "!tar -xf '/content/caltech-101/101_ObjectCategories.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torchvision import datasets\n",
        "from  torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "yrhsXGtOESum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Приводим изображение к \"стандартному размеру\"\n",
        "def resize(tensor, h = 256, w = 256):\n",
        "  return cv2.resize(tensor, [h, w], interpolation = cv2.INTER_CUBIC)"
      ],
      "metadata": {
        "id": "pIjs3KRQEUen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/101_ObjectCategories'\n",
        "\n",
        "# Все изображения сохранены в отдельных каталогах \"Название каталога(категория изображения)/img1\"\n",
        "# Расайзнем, переименнуем(в имени изображения содержится категория) и сохраним изображения в отдельный каталог\n",
        "\n",
        "def reorcan_set_in_random_Set(path):\n",
        "  list_dir = os.listdir(path)\n",
        "\n",
        "  for i in list_dir:\n",
        "    list_img = os.listdir(os.path.join(path, i))\n",
        "\n",
        "    for j in list_img:\n",
        "      img_patch = os.path.join(path, i, j)\n",
        "      img_list = img_patch.split('/')\n",
        "      if '.jpg' in img_patch:\n",
        "        img = cv2.imread(img_patch)\n",
        "        tensor = resize(img)\n",
        "        cv2.imwrite('/content/Image/' + '_'.join(img_list[3:]) , tensor)\n",
        "        \n",
        "reorcan_set_in_random_Set(path)"
      ],
      "metadata": {
        "id": "juTxmljxEYSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Прогонять изображания будем через encoder ResNet18(можно использовать любой)\n",
        "# Делаем на GPU, так как это в 6 раз бысрее для данной модели\n",
        "# CPU - 12 min, GPU - 2 min\n",
        "\n",
        "device = torch.device('cuda:0')\n",
        "model = resnet18(weights=ResNet18_Weights).to(device)\n",
        "path = '/content/Image'\n",
        "\n",
        "class clossly_set(Dataset):\n",
        "\n",
        "  def __init__(self, path, transforms = None):\n",
        "    self.image_set = os.listdir(path)\n",
        "    self.transforms = transforms\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_set)  \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    if torch.is_tensor(index):\n",
        "      index = index.tolist()\n",
        "\n",
        "    path_image = self.image_set[index]\n",
        "    image_name = path_image.split('.')[0]\n",
        "    \n",
        "    img = cv2.imread(os.path.join(path, path_image))\n",
        "    img = resize(img)\n",
        "\n",
        "    if self.transforms:\n",
        "      img = self.transforms(img)\n",
        "\n",
        "    # Возвращаем само изображение, переведенное в тензор,нормализованное и класс к которому относится это изображение \n",
        "    return img, image_name\n",
        "\n",
        "tr = transforms.Compose([\n",
        "         transforms.ToTensor(), \n",
        "         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])         \n",
        "    ])\n",
        "\n",
        "\n",
        "dataset = clossly_set(path = path, transforms = tr)\n",
        "\n",
        "#Заводим контейнер, в который будем складывать эмбединги изображений, ролученные на слое 'avgpool'\n",
        "layer = model._modules.get('avgpool')\n",
        "outputs = []\n",
        "\n",
        "#Функция для сбора эмбедингов\n",
        "def copy_embed(m,i,o):\n",
        "  o = o[0:, :, 0,0].detach().cpu().numpy()\n",
        "  outputs.append(o)\n",
        "\n",
        "# При прохождении слоя 'avgpool' - (layer) будет вызываться функции copy_embed\n",
        "# которая будет \"регестрировать\" прямой проход\n",
        "_ = layer.register_forward_hook(copy_embed)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size = 1)\n",
        "\n",
        "#Каждому эмбедингу соответствует лэйбл, складируем их в \"index\"\n",
        "index = []\n",
        "\n",
        "for iter, (x,y) in enumerate(dataloader):\n",
        "  x_gpu = x.to(device)\n",
        "  index.append(y)\n",
        "  _, =  model(x_gpu)\n",
        "\n",
        "# {'название изображения':'его эмбединг'}\n",
        "hash_emb = {}\n",
        "for i in range(len(index)):\n",
        "  hash_emb[index[i][0]] = outputs[i][0]"
      ],
      "metadata": {
        "id": "D3nZSlzCEeps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_data_frame = pd.DataFrame(hash_emb)"
      ],
      "metadata": {
        "id": "zGhlDYENElil"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}