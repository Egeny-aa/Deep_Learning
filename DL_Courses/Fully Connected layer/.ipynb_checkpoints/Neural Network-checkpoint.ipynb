{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of model failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Евгений\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Евгений\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Евгений\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1017, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 947, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Евгений\\dlcourse_ai\\assignments\\assignment2\\model.py\", line 131\n",
      "    def best_params(self)\n",
      "                         ^\n",
      "SyntaxError: expected ':'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Евгений\\AppData\\Local\\Temp\\ipykernel_10056\\2810386256.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
      "C:\\Users\\Евгений\\AppData\\Local\\Temp\\ipykernel_10056\\2810386256.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n"
     ]
    }
   ],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for W1\n",
      "Gradient check passed!\n",
      "Checking gradient for B1\n",
      "Gradient check passed!\n",
      "Checking gradient for W2\n",
      "Gradient check passed!\n",
      "Checking gradient for B2\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06666666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302157, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302153, Train accuracy: 0.114222, val accuracy: 0.147000\n",
      "Loss: 2.302324, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.303007, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301699, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301963, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302225, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302477, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302589, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301862, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302984, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302658, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301923, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302428, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301367, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303651, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302627, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301863, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301699, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x207d3886710>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.299640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306022, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242150, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304279, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290445, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.318655, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181615, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.376430, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284482, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.327744, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311656, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.331265, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208615, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275874, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265668, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239710, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.324248, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.312465, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250796, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.328707, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303246, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298436, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290073, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290023, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268230, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273707, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293853, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304481, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295980, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.340840, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300352, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262520, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245457, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282637, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247791, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237157, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276019, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223874, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.340310, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.350926, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.307062, Train accuracy: 0.266667, val accuracy: 0.066667\n",
      "Loss: 2.295739, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.336886, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.307335, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.317857, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.213127, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.257662, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.001195, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.107345, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.175777, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.057221, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.722861, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.379879, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.628495, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.700829, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.369766, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.751079, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.326074, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.743756, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.219150, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.391715, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.739757, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.782432, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.217827, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.279434, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.315712, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.498203, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 1.714299, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.353217, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.722217, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.226699, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.088908, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.016812, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.312803, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.761180, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.300006, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.446671, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.596846, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.467464, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.583256, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.745112, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.830148, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 2.188231, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.548247, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.393327, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.755262, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.303794, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.422253, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.502562, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.566893, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.143029, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.901582, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.583362, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.878742, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.553346, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.908586, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.244900, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.624946, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.319354, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.389632, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.062556, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.549215, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.331985, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.365091, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.646562, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.643826, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.402865, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.979571, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.327910, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.648651, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.503796, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.357618, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.020298, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.934040, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.443540, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.557903, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.633733, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.930361, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.272065, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.704810, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.263836, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.834400, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.202752, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.598033, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.560696, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.112316, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.385604, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.586410, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.268663, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.957099, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.365305, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 0.956720, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.367527, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.413182, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.357701, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.546296, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.780756, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.226231, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.650855, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.257404, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.555041, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.442716, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.441679, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.464228, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.473569, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.257416, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.422412, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.398090, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.310977, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.262904, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.271784, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.929796, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.616884, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.164721, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.094712, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.422808, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.174618, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.727351, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.760114, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.198437, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.508246, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.548631, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.367811, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.592163, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.142960, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.933794, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.091866, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.658186, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.013647, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.246147, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.114209, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327382, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.205241, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.187900, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.579235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.037093, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.169284, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.265539, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.132535, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.467876, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.569426, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.262520, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.359760, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.107987, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391521, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.417316, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.295834, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.984507, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.316744, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.226603, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199999, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.234146, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.565598, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883295, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.731349, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.186561, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 0.818259, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 0.768484, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 0.711071, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.164382, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.289192, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.163643, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 0.002803, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 0.000353, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.109346, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.000050, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.000125, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 0.001615, Train accuracy: 1.000000, val accuracy: 0.066667\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 200, reg = 0)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Loss: 2.300906, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297521, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299292, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295056, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293030, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291737, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288045, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279339, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294439, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284248, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "2\n",
      "Loss: 2.230053, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.057640, Train accuracy: 0.272556, val accuracy: 0.274000\n",
      "Loss: 1.774554, Train accuracy: 0.416000, val accuracy: 0.415000\n",
      "Loss: 1.238192, Train accuracy: 0.490778, val accuracy: 0.493000\n",
      "Loss: 1.648300, Train accuracy: 0.555333, val accuracy: 0.553000\n",
      "Loss: 1.423947, Train accuracy: 0.608000, val accuracy: 0.598000\n",
      "Loss: 1.110271, Train accuracy: 0.621333, val accuracy: 0.604000\n",
      "Loss: 1.604031, Train accuracy: 0.642222, val accuracy: 0.625000\n",
      "Loss: 1.125019, Train accuracy: 0.665444, val accuracy: 0.644000\n",
      "Loss: 0.843579, Train accuracy: 0.671667, val accuracy: 0.653000\n",
      "3\n",
      "Loss: 2.298272, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278731, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277005, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290336, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260845, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277265, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301898, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258881, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284249, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "4\n",
      "Loss: 2.256640, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277254, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.158618, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261915, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.392192, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.149699, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243387, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.045770, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.359489, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.403366, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "5\n",
      "Loss: 2.291972, Train accuracy: 0.181000, val accuracy: 0.196000\n",
      "Loss: 2.443634, Train accuracy: 0.157222, val accuracy: 0.148000\n",
      "Loss: 2.369870, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315849, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.311725, Train accuracy: 0.167444, val accuracy: 0.180000\n",
      "Loss: 2.236616, Train accuracy: 0.153333, val accuracy: 0.148000\n",
      "Loss: 2.344481, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.371863, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.372156, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.389742, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "best validation accuracy achieved: 0.653000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "from random import choice\n",
    "num_inter = 5\n",
    "\n",
    "learning_rates = [1e-1,1e-2,1e-3,1e-4]\n",
    "reg_strength = [1e-1,1e-2, 1e-3, 1e-4]\n",
    "learning_rate_decay = [0.8, 0.9, 0.999]\n",
    "hidden_layer_size = [128, 228, 328]\n",
    "num_epochs = 10\n",
    "batch_size = [64,15,45,25]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "best_loss_history = {}\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "data = Dataset(train_X, train_y, val_X, val_y)\n",
    "\n",
    "for i in range(num_inter):\n",
    "    print(i+1)\n",
    "    ln = choice(learning_rates)\n",
    "    rs = choice(reg_strength)\n",
    "    lrd = choice(learning_rate_decay)\n",
    "    hls = choice(hidden_layer_size)\n",
    "    bs = choice(batch_size)\n",
    "    model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = hls, reg = rs)\n",
    "    \n",
    "    trainer = Trainer(model, data, MomentumSGD(), num_epochs=num_epochs,\n",
    "                 batch_size = bs,\n",
    "                 learning_rate = ln,\n",
    "                 learning_rate_decay = lrd) \n",
    "    \n",
    "    loss, train_his, val_his = trainer.fit()\n",
    "    \n",
    "    if loss_history == []:\n",
    "        loss_history = loss\n",
    "        train_history = train_his\n",
    "        val_history = val_his\n",
    "        \n",
    "    elif loss[-1] < loss_history[-1]:\n",
    "        best_giper_params = {'batch_size':bs, \n",
    "                             'learning_rate':ln,\n",
    "                             'reg_strength':rs,\n",
    "                             'learning_rate_decay':lrd,\n",
    "                            'hidden_layer_size':hls}\n",
    "        \n",
    "        loss_history = loss\n",
    "        train_history = train_his\n",
    "        val_history = val_his\n",
    "        \n",
    "        \n",
    "    best_loss_history[loss[-1]] = model\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "best_best_classifier = best_loss_history[min(loss_history)]\n",
    "\n",
    "best_val_accuracy = max(val_history)\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 25,\n",
       " 'learning_rate': 0.01,\n",
       " 'reg_strength': 0.001,\n",
       " 'learning_rate_decay': 0.8,\n",
       " 'hidden_layer_size': 128}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_giper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x207ec452a10>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.622000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
